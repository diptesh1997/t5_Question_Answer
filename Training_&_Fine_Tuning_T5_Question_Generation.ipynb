{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Packages"
      ],
      "metadata": {
        "id": "vgLD40jt867A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMeOslZ9Qxlx"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet  datasets #to access race dataset\n",
        "!pip install --quiet pyarrow   #to deal with parquet files for saving dataset if required\n",
        "!pip install --quiet  tqdm     #for progress bars\n",
        "!pip install --quiet transformers # for t5 model\n",
        "!pip install --quiet tokenizers  #tokenizers from HuggingFace\n",
        "!pip install --quiet sentencepiece #subword tokenizer used by T5\n",
        "!pip install --quiet pytorch-lightning # pytorch wrapper\n",
        "!pip install --quiet torchtext # text utilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhbOe_M7omZN",
        "outputId": "f9cd5c75-085c-44a1-9870-f2f9372a6ec4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnkwYBQ6TWB4"
      },
      "source": [
        "# Fetching Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QnjddTNlS6Dz"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pprint import pprint\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fetching Custom Dataset"
      ],
      "metadata": {
        "id": "l_bE1EaCaA32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "import pandas as pd\n",
        "#uploaded = files.upload()\n",
        "#df2 = pd.read_csv(io.BytesIO(uploaded['Dataset - Sheet1.csv']))\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Dataset - Sheet1.csv')"
      ],
      "metadata": {
        "id": "ZUpgJTAcTZHP"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df2.iloc[0:177, 1:4]\n",
        "df3"
      ],
      "metadata": {
        "id": "Ft2VLImaVCGb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c3558a38-f11d-4cb4-ff29-a9654be76198"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Context  \\\n",
              "0    We present QuAC, a dataset for Question Answer...   \n",
              "1    We present QuAC, a dataset for Question Answer...   \n",
              "2    We present QuAC, a dataset for Question Answer...   \n",
              "3    We present QuAC, a dataset for Question Answer...   \n",
              "4    In information-seeking dialog, students repeat...   \n",
              "..                                                 ...   \n",
              "172  Photo sites such as Flickr are a rich source o...   \n",
              "173  Photo sites such as Flickr are a rich source o...   \n",
              "174  Photo sites such as Flickr are a rich source o...   \n",
              "175  Photo sites such as Flickr are a rich source o...   \n",
              "176  Photo sites such as Flickr are a rich source o...   \n",
              "\n",
              "                                              Question  \\\n",
              "0             What is the purpose of the QuAC dataset?   \n",
              "1    How are the dialogs in the QuAC dataset struct...   \n",
              "2    What are some unique challenges presented by t...   \n",
              "3    How does the performance of the best model on ...   \n",
              "4    How does the QuAC dataset encourage natural an...   \n",
              "..                                                 ...   \n",
              "172  What is the source of labeled data used in the...   \n",
              "173  How does user-generated metadata differ from m...   \n",
              "174  What is the approach for representing image fe...   \n",
              "175  How is the conditional adversarial net trained...   \n",
              "176  How are the results of the image tagging exper...   \n",
              "\n",
              "                                                Answer  \n",
              "0    The QuAC dataset was created for Question Answ...  \n",
              "1    The dialogs in the QuAC dataset involve a stud...  \n",
              "2    The QuAC dataset introduces several challenges...  \n",
              "3    The best model evaluated on the QuAC dataset f...  \n",
              "4    The QuAC dataset promotes natural and diverse ...  \n",
              "..                                                 ...  \n",
              "172  The source of labeled data used in the image t...  \n",
              "173  User-generated metadata, such as user-tags, ar...  \n",
              "174  Image features are represented using a pre-tra...  \n",
              "175  The convolutional model and language model use...  \n",
              "176  For evaluation, 100 samples are generated for ...  \n",
              "\n",
              "[177 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-516075ea-bcb0-4060-94a0-045ad550740c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We present QuAC, a dataset for Question Answer...</td>\n",
              "      <td>What is the purpose of the QuAC dataset?</td>\n",
              "      <td>The QuAC dataset was created for Question Answ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>We present QuAC, a dataset for Question Answer...</td>\n",
              "      <td>How are the dialogs in the QuAC dataset struct...</td>\n",
              "      <td>The dialogs in the QuAC dataset involve a stud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We present QuAC, a dataset for Question Answer...</td>\n",
              "      <td>What are some unique challenges presented by t...</td>\n",
              "      <td>The QuAC dataset introduces several challenges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We present QuAC, a dataset for Question Answer...</td>\n",
              "      <td>How does the performance of the best model on ...</td>\n",
              "      <td>The best model evaluated on the QuAC dataset f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In information-seeking dialog, students repeat...</td>\n",
              "      <td>How does the QuAC dataset encourage natural an...</td>\n",
              "      <td>The QuAC dataset promotes natural and diverse ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>Photo sites such as Flickr are a rich source o...</td>\n",
              "      <td>What is the source of labeled data used in the...</td>\n",
              "      <td>The source of labeled data used in the image t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>Photo sites such as Flickr are a rich source o...</td>\n",
              "      <td>How does user-generated metadata differ from m...</td>\n",
              "      <td>User-generated metadata, such as user-tags, ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>Photo sites such as Flickr are a rich source o...</td>\n",
              "      <td>What is the approach for representing image fe...</td>\n",
              "      <td>Image features are represented using a pre-tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>Photo sites such as Flickr are a rich source o...</td>\n",
              "      <td>How is the conditional adversarial net trained...</td>\n",
              "      <td>The convolutional model and language model use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>Photo sites such as Flickr are a rich source o...</td>\n",
              "      <td>How are the results of the image tagging exper...</td>\n",
              "      <td>For evaluation, 100 samples are generated for ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>177 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-516075ea-bcb0-4060-94a0-045ad550740c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-516075ea-bcb0-4060-94a0-045ad550740c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-516075ea-bcb0-4060-94a0-045ad550740c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25126a14-b98b-481b-b7be-3cb81c2f7d03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25126a14-b98b-481b-b7be-3cb81c2f7d03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25126a14-b98b-481b-b7be-3cb81c2f7d03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df3",
              "summary": "{\n  \"name\": \"df3\",\n  \"rows\": 177,\n  \"fields\": [\n    {\n      \"column\": \"Context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \" The proposed question\\u2013answer pair generation system takes a context passage as input and creates a list of questions on content knowledge with the extracted answers as output. The approach starts with loading textual context over which question\\u2013answer pairs have to be generated. The text uploaded can be a single-sentence or multi-sentence passage. This text is then passed to the next block, where it is pre-processed and split into sentences using a sentential tokenizer. These text tokens are then fed to the next block to obtain the position of each sentence in the context. These positions are attained using positional embeddings. Then, the sentence which contains answers is realized and highlighted using token and task prefixes are appended to the context with the highlighted sentence. The length padding or truncation is performed before applying the fine-tuned T5 model for answer extraction. After applying the model, a list of answers has been obtained and joined. The embeddings for these extracted answers are obtained along with their corresponding positional embeddings. The task prefixes are appended and the length padding or truncation is performed. Then, the fine-tuned T5 model has been applied to generate the questions that matched the text in the context. Finally, a list of question\\u2013answer pairs has been obtained that are grammatically and contextually correct. These generated question\\u2013answer pairs facilitate teachers in developing instructional content for various domains. Also, automating the process of tests creation helps tutors for academic purposes and students with their self-evaluation. The rest of this paper is organized as follows: Section 2 presents a brief overview of the existing approaches to question generation and answer extraction tasks. The architecture of the question\\u2013answer generation system and the design of each module is discussed in Sect. 3. The algorithms behind the implementation of each module are also explored. The evaluation results obtained for the system are presented in Sect. 4. Section 5 draws the conclusion along with the future scope of work.\",\n          \"Qualitative evaluation\\nIn this section, we investigate the e\\u2000ect of the guidance network whether it\\n1) yields the degradation in visual quality, 2) induces a meaningful manifold\\nmapping, and 3) results in the memorization of Pdata.\\nFirst, we compare generated images from baseline models and the corresponding\\nMGGANs. Figure 5 visualizes those results; the left side shows the\\ngenerated images from the baseline GAN while the right side presents those\\nfrom the MGGAN. From this qualitative comparison, it is hard to recognize the\\nquality di\\u2000erence from both results. Therefore, our achievement in improving the\\nimage diversity is not the result of sacri\\u2000cing the visual quality. These results\\nare analogous to the quantitative evaluation reported in Fig. 4.\\nSecond, we exam whether our weakly bidirectional mapping can induce a\\nmeaningful cycle between data and a latent vector z or not. For that, we build\\nan additional network that associates our manifold space Pm to a latent space\\nPz. Because this network transforms the encoder output to a latent vector, we\\ncould track a cyclic mapping. That is, z ) x ) m ) z. This path can be\\nconsidered as the detours to build a bidirectional mapping. Although this additional\\nnetwork is never utilized during our training, we intentionally develop\\nthis network to derive bz corresponding to x, and then reconstruct x using the\\ngenerator G(bz).Based on this reconstruction experiment, we can evaluate how\\naccurate our model can reproduce the real data, even without explicitly imposing\\nthe reconstruction loss. A network to link Pm and Pz is composed of 1024 full\\nconnected layer(FC) \\udbc0\\udc00 batch normalization(BN) \\udbc0\\udc00 recti\\u2000ed linear unit(ReLU)\\n\\udbc0\\udc00 1024 FC \\udbc0\\udc00 BN \\udbc0\\udc00 ReLU \\udbc0\\udc00 dimension of Pz FC. Figure 6 shows the reconstructed\\nimages with their target images. They are from CelebA test dataset\\nand four variants (DCGAN-MG, LSGAN-MG, DRAGAN-MG, and DFM-MG)\\nare all investigated. For the performance comparison with bidirectional mapping\\napproaches, we borrow the result image of ALI from their paper [11]. Odd\\ncolumns show target images and even columns are their reconstructed images.\\nThe results from ALI do not faithfully restore the attribute of target faces, such\\nas gender, glasses, and background color. On the contrary, our MGGANs reproduce\\ntarget images reasonably well, maintaining the original attribute. From this\\nexperiment, it is possible to con\\u2000rm that our MGGAN produces more accurate\\nreconstruction results than the bidirectional mapping approach, ALI.\\nThird, we generate samples by walking in latent space to verify whether data\\ngeneration is the results of data memorization or not. Because our generator\\nlearns representative features in manifold, Pm, derived from Pdata solely, it might\\nbe reasonable to suspect over\\u2000tting of training data. To clarify this issue, image\\ngeneration results by latent walking are shown in Fig. 7. Note that we choose two\\nlatent vectors, which are derived from CelebA test data using the above network\\n(connecting the manifold to the latent space). According to Radford et al. [20]\\n, Bengio et al. [24], and Dinh et al.[25], the interpolated images between two\\nimages in latent space do not have meaningful connectivity when the networks\\njust memorize the dataset: such as lack of smooth transitions or fail to generation.\\nHowever, because our MGGAN produces natural interpolations with various\",\n          \"4.2 Quantitative evaluation\\nFor evaluating the e\\u2000ectiveness of our MGGAN, we construct four variants of\\nMGGAN. That is, we select four di\\u2000erent GANs as baseline networks, and then\\nmodify each by adding the guidance network. Those of baseline GANs report\\nthe state of the art visual quality in data generation, but are prone to mode\\ncollapse. Throughout this paper, we utilize four baseline networks as DCGAN\\n[20], LSGAN [10], DRAGAN [9], and DFM [21], and develop the variants of\\nMGGAN as DCGAN-MG, LSGAN-MG, DRAGAN-MG, and DFM-MG. For the\\nfair comparison, the network architecture of both a generator and a discriminator\\nfollows that of DCGAN. Also, we utilize suggested hyperparameters from each\\nbaseline work without any \\u2000ne-tune. Implementation code is available soon.\\nMS-SSIM [22] and the inception score [23] are used as metrics for quantitative\\nevaluation. These demonstrate that MGGAN improves the diversity of data\\ngeneration while retaining the image quality of baseline GANs. The smaller MSSSIM\\nimplies the better performance in producing diverse images. The inception\\nscore is used to assess the visual quality of GANs using the CIFAR-10 dataset,\\nand the larger score represents the higher quality.\\nTo evaluate the image diversity using MS-SSIM, we only use the CelebA\\ndataset. CIFAR-10 is excluded from this experiment, because MS-SSIM is meaningless\\nif the dataset is already highly diverse [3]; CIFAR-10 is composed of ten\\ndi\\u2000erent classes. To compare four variants of MGGAN with their baseline GANs,\\nwe measure MS-SSIM for 100 samples generated from four baseline GANs with\\nand without the guidance network. Table 1 summarizes the average score of\\nMS-SSIM measurements repeated ten times for each model. From this experiment,\\nwe \\u2000nd that four variants of our MGGAN signi\\u2000cantly improves the\\nimage diversity (i.e., reduced MS-SSIM) compared to the baseline GANs all the\\ntime. Furthermore, the MS-SSIM values of all MGGANs are close to that of real\\ndata (i.e., 0.3727). This justi\\u2000es that the proposed model is e\\u2000ective to handle\\nthe mode collapse. It is because the level of image diversity from the proposed\\nmodel nearly approaches to its optimal limit, the image diversity of real dataset.\"\n        ],\n        \"num_unique_values\": 54,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"How is the visual quality of generated images compared between the baseline GANs and MGGANs?\",\n          \"What is the objective of training the generative model (G) and the discriminative model (D) in the adversarial nets framework?\",\n          \"How did CO-Search perform in the TREC-COVID information retrieval challenge?\"\n        ],\n        \"num_unique_values\": 175,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"The QuAC evaluation accounts for questions with multiple valid answers by computing the maximum F1 score across all reference annotations, similar to SQuAD. However, since the number of references can vary for each question, this metric can be influenced by the number of annotations. To ensure fair comparison between human and system performance, the average of the maximum F1 scores is computed from each subset of references. This approach normalizes the evaluation metric and reduces its sensitivity to the number of reference annotations, enabling a more reliable assessment of system performance.\",\n          \"The complementarity evaluation process in the question-answering learning method aims to identify a subset of N4 mutually complementary sentences from the previously selected N3 sentences. The N4 sentences are chosen to be labeled and further analyzed. These sentences possess specific attributes, including being non-repetitive, dissimilar, non-implicative, and non-derivative. This selection ensures that the labeled sentences offer unique and distinct information, avoiding redundancy or similarity to previously selected sentences. The complementarity evaluation process plays a critical role in diversifying the labeled data and enhancing the overall performance of the question-answering system.\",\n          \"The adversarial nets framework sidesteps the difficulties associated with traditional generative models that rely on approximating intractable probabilistic computations. Instead, it introduces an adversarial process where the generative model competes against the discriminative model. This framework allows for the discovery of rich, hierarchical generative models without the need for Markov chains or unrolled approximate inference networks.\"\n        ],\n        \"num_unique_values\": 176,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filename,  verbose = False):\n",
        "  data  = pd.read_csv(filename, skipinitialspace=True, usecols=['Context','Question','Answer'] )\n",
        "  result_df1  = pd.DataFrame(columns = ['context', 'question','answer'])\n",
        "  result_df1 = data\n",
        "  return result_df1"
      ],
      "metadata": {
        "id": "dUeWslZzV4WK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, valid = train_test_split(df2, test_size=0.3)\n",
        "#valid, test = train_test_split(temp, test_size=0.1)"
      ],
      "metadata": {
        "id": "Naf34hAqV4jr"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pandas_dataset1(data, answer_threshold=512, verbose=False):\n",
        "    count_long, count_short = 0, 0\n",
        "    result_df = pd.DataFrame(columns=['context', 'question', 'answer'])\n",
        "    for val in tqdm(data):\n",
        "        if 'Context' in val and 'Question' in val and 'Answer' in val:\n",
        "            passage = val['Context']\n",
        "            question = val['Question']\n",
        "            answer = val['Answer']\n",
        "            no_of_words = len(answer.split())\n",
        "            if no_of_words >= answer_threshold:\n",
        "                count_long += 1\n",
        "                continue\n",
        "            else:\n",
        "                result_df.loc[count_short] = [passage, question, answer]\n",
        "                count_short += 1\n",
        "        else:\n",
        "            continue\n",
        "    if verbose:\n",
        "        return result_df, count_long, count_short\n",
        "    else:\n",
        "        return result_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OQ9jKLS1xkov"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train1 , df_validation1 = create_pandas_dataset1(train) , create_pandas_dataset1(valid)\n",
        "print(f\"\\n Total Train Samples:{df_train1.shape} , Total Validation Samples:{df_validation1.shape}\")"
      ],
      "metadata": {
        "id": "3uzYSdXOboDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "INC4ECm5AFip"
      },
      "outputs": [],
      "source": [
        "device  = 'cuda' if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "snPR6qxi-PxA"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_rows , pd.options.display.max_columns  = 100,100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqctRHUeLk0M"
      },
      "source": [
        "#Importing Race Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Ra4F3pizTZ-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af1cb7d-08ef-4e30-edea-76dad55f3ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Train Samples:25421 , Total Validation Samples:1436\n"
          ]
        }
      ],
      "source": [
        "train_dataset = load_dataset('race','middle', split='train')\n",
        "valid_dataset = load_dataset('race', 'middle', split='validation')\n",
        "print(f\"Total Train Samples:{len(train_dataset)} , Total Validation Samples:{len(valid_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "LD7O9vasveLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3350d1-50da-4122-e776-5b22797e5c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['example_id', 'article', 'answer', 'question', 'options'],\n",
            "    num_rows: 25421\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pandas_dataset(data,\n",
        "                          answer_threshold=512,\n",
        "                          verbose = False):\n",
        "\n",
        "  count_long ,count_short = 0 , 0\n",
        "  result_df  = pd.DataFrame(columns = ['context', 'question','answer'])\n",
        "  #print(data)\n",
        "  for index,val in enumerate(tqdm(data)):\n",
        "      passage = val['article']\n",
        "      question = val['question']\n",
        "      ans = val['answer']\n",
        "      answer = val['options'][ord(ans)-65]\n",
        "      no_of_words = len(answer.split())\n",
        "      if no_of_words >= answer_threshold:\n",
        "          count_long = count_long + 1\n",
        "          continue\n",
        "      else:\n",
        "          result_df.loc[count_short] = [passage] +[question] + [answer]\n",
        "          count_short = count_short + 1\n",
        "  if verbose:\n",
        "    return (result_df,\n",
        "            count_long,\n",
        "            count_short)\n",
        "  else:\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "YhuswG4I44Xe"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "JGH_ObQA0j3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbab79e-87fa-47be-a813-1630c0652863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['example_id', 'article', 'answer', 'question', 'options'],\n",
            "    num_rows: 25421\n",
            "})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25421/25421 [01:06<00:00, 382.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['example_id', 'article', 'answer', 'question', 'options'],\n",
            "    num_rows: 1436\n",
            "})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1436/1436 [00:03<00:00, 359.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total Train Samples:(25421, 3) , Total Validation Samples:(1436, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "df_train , df_validation = create_pandas_dataset(train_dataset) , create_pandas_dataset(valid_dataset)\n",
        "print(f\"\\n Total Train Samples:{df_train.shape} , Total Validation Samples:{df_validation.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49j_Kx6A5cb0"
      },
      "outputs": [],
      "source": [
        "# Saving data for future use\n",
        "df_train.to_parquet('train_race.parquet')\n",
        "df_validation.to_parquet('validation_race.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After saving we can run this file to read from drive"
      ],
      "metadata": {
        "id": "B4_apmqJgwB-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "yrdjFLeKHNpY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "44553fe0-2039-4653-f697-2efc46c36330"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 context  \\\n",
              "0      Last week I talked with some of my students ab...   \n",
              "1      Last week I talked with some of my students ab...   \n",
              "2      Last week I talked with some of my students ab...   \n",
              "3      Last week I talked with some of my students ab...   \n",
              "4      YUZHOU, HENAN -An accident in a central China ...   \n",
              "...                                                  ...   \n",
              "62440  What if I took that big jump on my bike?What's...   \n",
              "62441  What if I took that big jump on my bike?What's...   \n",
              "62442  What if I took that big jump on my bike?What's...   \n",
              "62443  When officials in Richmond, B. C., Canada, tol...   \n",
              "62444  When officials in Richmond, B. C., Canada, tol...   \n",
              "\n",
              "                                                question  \\\n",
              "0      We can know from the passage that the author w...   \n",
              "1      Many graduates today turn to cosmetic surgery ...   \n",
              "2      According to the passage, the author believes ...   \n",
              "3              Which' s the best title for the passage?.   \n",
              "4         What could be the best title for this passage?   \n",
              "...                                                  ...   \n",
              "62440  According to the text,the teenager who explore...   \n",
              "62441  What does the writer want to tell us by taking...   \n",
              "62442        What may the text discuss in the next part?   \n",
              "62443  Stephen Covey was doubtful at first because he...   \n",
              "62444  In covey's first opinion, people in Richmond, ...   \n",
              "\n",
              "                                                  answer  \n",
              "0                                                teacher  \n",
              "1            get an advantage over others in job-hunting  \n",
              "2      media are to blame for misleading young people...  \n",
              "3        Young Graduates Look to Surgery for Better Jobs  \n",
              "4                  A Coal Mine Accident in Central China  \n",
              "...                                                  ...  \n",
              "62440                       have advantages over others.  \n",
              "62441  Mice also experience a period to explore the w...  \n",
              "62442          What really goes on in the teenage brain.  \n",
              "62443  youth crime was too complex for ordinary citiz...  \n",
              "62444            had no ability to make great difference  \n",
              "\n",
              "[62445 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-525fb7b9-a5a8-4367-872c-db31b904108b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Last week I talked with some of my students ab...</td>\n",
              "      <td>We can know from the passage that the author w...</td>\n",
              "      <td>teacher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Last week I talked with some of my students ab...</td>\n",
              "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
              "      <td>get an advantage over others in job-hunting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Last week I talked with some of my students ab...</td>\n",
              "      <td>According to the passage, the author believes ...</td>\n",
              "      <td>media are to blame for misleading young people...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Last week I talked with some of my students ab...</td>\n",
              "      <td>Which' s the best title for the passage?.</td>\n",
              "      <td>Young Graduates Look to Surgery for Better Jobs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
              "      <td>What could be the best title for this passage?</td>\n",
              "      <td>A Coal Mine Accident in Central China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62440</th>\n",
              "      <td>What if I took that big jump on my bike?What's...</td>\n",
              "      <td>According to the text,the teenager who explore...</td>\n",
              "      <td>have advantages over others.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62441</th>\n",
              "      <td>What if I took that big jump on my bike?What's...</td>\n",
              "      <td>What does the writer want to tell us by taking...</td>\n",
              "      <td>Mice also experience a period to explore the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62442</th>\n",
              "      <td>What if I took that big jump on my bike?What's...</td>\n",
              "      <td>What may the text discuss in the next part?</td>\n",
              "      <td>What really goes on in the teenage brain.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62443</th>\n",
              "      <td>When officials in Richmond, B. C., Canada, tol...</td>\n",
              "      <td>Stephen Covey was doubtful at first because he...</td>\n",
              "      <td>youth crime was too complex for ordinary citiz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62444</th>\n",
              "      <td>When officials in Richmond, B. C., Canada, tol...</td>\n",
              "      <td>In covey's first opinion, people in Richmond, ...</td>\n",
              "      <td>had no ability to make great difference</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62445 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-525fb7b9-a5a8-4367-872c-db31b904108b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-525fb7b9-a5a8-4367-872c-db31b904108b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-525fb7b9-a5a8-4367-872c-db31b904108b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eff6f832-f441-405f-8840-da37929789b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eff6f832-f441-405f-8840-da37929789b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eff6f832-f441-405f-8840-da37929789b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 62445,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Every athlete,from Tiger Woods(a golf player)to a high school quarterback ,uses a form of self-hypnosis to move their game to the next level Use the Olympics to 1earn how to use the amazing power of your subconscious to do the same with your sport.\\nHere are some examples of how to best use the power of the mind:\\nDuring the 2004 Olympics,one of the swimmers told of how she would fall asleep each night with the picture of a clock in her mind. It was the timer's clock she would see at the end of her Olympic swim and it always had her world-record-breaking time on it.\\nIn his pre-shot routine, Tiger Woods never varies the number of practice swings or intensity of his concentration.The pre-shot routine is always the same so that the stroke will always be the same.\\nMichael Phelps,American Swimming Gold Medalist, always stretches out his back and arms by swinging both arms three times before his event. Not 2,not 4: always 3. He is anchoring in his winning state of mind and state of body as well as stretching.\\nIn athletics, an anchor is a gesture or series of gestures that put you into the frame-of mind(and body)you want to be in to win.Repetition is what makes it work .That means practice,practice,practice ---- with your body as well as your mind.\\nBegin right now creating a ritual before you exercise.Visualize yourself doing whatever you do faster, longer, higher--whatever adverb works best for your particular activity. Then begin to mentally practice it. See or imagine yourself-----with your ideal body ---- doing your activity better, faster, longer, etc. Using both the power of your brain and the activity of your body, soon you will be better and fitter as you use the Olympics to help you create a happier and healthier you.\",\n          \"Whether you're having problems with your homework or you're preparing for your term paper, these student-focused websites can help you with anything you need. The key to getting the most out of these online resources is to know how they can best be used to your advantage.\\n Facebook\\nAlthough Facebook can be one of your biggest time-wasters and distractions when you are supposed to be getting work done, it can also be one of your most valuable resources. Most of your classmates will probably have a Facebook account, so anyone you need to connect with about a class you missed or about a problem is usually just a few clicks away.\\n SparkNotes\\nWith a free library of history timeline, philosophy study guides and library summaries, and essays, SparkNotes has covered just about any reading-related jam you find yourself in, just run a search for the book, play, or short summary of the material you are supposed to read.\\n Amazon.com\\nDo you finish every term with many expensive textbooks you will never open again? Instead of letting the money spent go to waste, get back some of your cash by selling your books on Amazon.\\nWikipedia\\nWhile Wikipedia isn't aimed specifically at students, it is difficult to think of another website that does more to reduce the pain of paper writing and researching. Wikipcdia gives you a quick way to find sources and get the details of almost any topic you need to research-----all without walking to the library.\",\n          \"It's high time someone spoke up for today's college students. They're probably the most hardworking, ambitious people in America and their problems are not properly appreciated.\\nPeople like the Secretary of Education simply don't know what they're talking about when they knock students. Nor do those who complain about falling academic standards.\\nThe vast majority of the nation's 12 million students are struggling to pay for their educations. They are part of the invisible workforce. Many hold down full-time jobs. They're frying hamburgers, photographing weddings, working in construction, and waiting on tables. The fact that they even show up for classes is a wonderful event.\\nThe financial situation of most students explains a lot about what is happening in schools.  Why are the traditional courses so unpopular? Why are students flocking to accounting and computer science and any professional programs that seem to lead to careers?\\nAnswer: Today's working student has been forced into a kind of premature matter-of-fact way of viewing things. Romance is gone. The notion of transforming one's self through study alone has disappeared. Today's students seek freedom from manual labor, and the status conferred by a good job.\\nThere are other consequences. Today's students don't have much time or energy to be devoted, and carry out independent research or even do serious homework. That's the secret behind falling academic standards. Students have become consumers. They want grades and certifications.  Their professors can't be expected to give a grade of failure to students who are clearly tired from the effort to pay their bills.\\nThere's a lot wrong with this situation. It's twisting the definition of education out of shape.  Worse, it's creating a generation that is totally unpleasant. The brightest students turn out to be yuppies  . The vast majority are, at least, good-natured semi-literates.\\nThe time has run out for philosophical debates about fixed courses of study. What this country needs is someone to stand up and say that being a full-time student during one's formative years is an honorable calling worthy of support. If families can't or won't give it to their children, then the government should.\"\n        ],\n        \"num_unique_values\": 18726,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"What does the author think of oceans?\",\n          \"Which was the best way for the fishing company to keep fishes fresh?\",\n          \"Which of the following can be the best title of the news text?\"\n        ],\n        \"num_unique_values\": 50917,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Get customers informed when they're near the limit of their plan.\",\n          \"Attention should be paid to the education of the only child\",\n          \"value her  s and friends more\"\n        ],\n        \"num_unique_values\": 57217,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.read_parquet('/content/drive/MyDrive/train_race.parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnhad7usfJiK"
      },
      "source": [
        "# Creating a Pytorch DataSet for T5 Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "7y_Ver9Eg26r"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7JNUExtpgrNS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "06adce485b0e49699cf6ab7ee480daf5",
            "8fa92abd28534546831e30f92c0f8ff5",
            "1c08e0afafff404dbb7b42160c58d0b2",
            "5e70a35f261640f9b7dc4facf987916f",
            "d76c6eba3a3b41afb7545005404aa5ce",
            "a543a44b457d4df28b73ae2d80a9b4cb",
            "2d0ba6d8771049f8bbcb9060a55848d8",
            "a8880954aa2844ee989501038cae969a",
            "244adbdd138c496a8412417d189b9c41",
            "354124fe2c694a3bb834cddf31b6ca68",
            "3e944c4debff46a2b98ee4546e996b1c",
            "c407eb69e32a4414809e458a1a7d6b59",
            "3a14b4fb73e148d29f3f836707f1cd30",
            "272f8d36b5f54b34b28a55aff4f77213",
            "9c7ce581b23a43df86110a9ead75e441",
            "3c9dcc13424942eb99147ce99ec0ff29",
            "05d561390b81440991bcd2c75af1f5cd",
            "a047c26c75ad4027bea05ea2025be993",
            "6bd30769bfeb4dc5a26dfabef56bdd41",
            "077d0ea97f504584b9664ca1b6e83626",
            "748e07caa91d4fdd903db0fb8d9c1d59",
            "630d98829b8349ef95b656aa24d51bca",
            "36df9018f5d74de18638b9b654067a87",
            "8d0b6b3bee534a5d9cdfb8c725e12ef1",
            "7d48ac0b9571478894537b65417b3e77",
            "270ff8167ce54072b856be7582c36399",
            "5cda07d095e34acea382d8b93fac54a6",
            "734da418a67647f8bf6b4bd68177db27",
            "5e444fc946e243168b37c1eaf2c2a7c8",
            "dc8419dde4134681b1b40ac365229860",
            "4f36897f3feb4e939278dd912ec485df",
            "a2960399a1f54ea88c18f2b57bdff101",
            "666b3246cc18495984edc8d1a9b44cbe",
            "f63f11d4689440f695b267f0675714aa",
            "bb803429d58c4b288dfd5c294dc5d82e",
            "850fcea279574cf3b40598020f9221cc",
            "b58ea7e273814338980a5e52944e90fb",
            "076cdb545c3a4027a3ae2b648508854e",
            "ed5d5bbf6d9549889bcd3ee3d2b28b90",
            "6bfbe3d10dd544628ee2810c69edb9e2",
            "b53a404631444bc195fd82c1c2f11f06",
            "57246cf8e0294111b923ed957a728061",
            "925ac27bf80041c48359b2ff9f0259ea",
            "72118739cb6b40d5b06762c59c7806a6",
            "773adce8b8ed4b82849164950cc1aeac",
            "92c7622eee1349fea36e757f779b56bf",
            "631946a44fb449b8a00f5fa745375e68",
            "7de536c8889143d88e608f84ab8bdebd",
            "97c0bf0a859243bf8a14a879429140d7",
            "a58f99e8186f44edad8bb447364b624a",
            "c54cdcc1a6544d6083191880ce321d52",
            "06d70c31a2ba458e9973acc02755f7af",
            "9ff3c43015d944329a47bb65beff4b94",
            "7c0533193bb941f78d7f54884c86e285",
            "79705a8967de4fc5af5c9cb703afdc3a",
            "afe17bba9f044b70a833de0d86f64a31",
            "09d70d6bf7894e8aac253007737cedcb",
            "0e9b47eb6f394dc98984408112605222",
            "814975cee07645fabaad51c19734e654",
            "5e7a53a62687491db7334d225b3f9855",
            "aea08997b1cd4c8ab016709896cdb1ef",
            "0c122d7d3c114fa48a3e16a35fa8a3e3",
            "2a2a37aa1cd14e1bb5a4e18b7380aa83",
            "20cf12072faf4cbb8a681f7b96547835",
            "ed91704ad46e41b18154ec8a10d15a50",
            "b8b23703f56b4bb5a452ebc226fc4dd1"
          ]
        },
        "outputId": "93635ec0-6535-4be9-a376-bc99eaafbef3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06adce485b0e49699cf6ab7ee480daf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c407eb69e32a4414809e458a1a7d6b59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36df9018f5d74de18638b9b654067a87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f63f11d4689440f695b267f0675714aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "773adce8b8ed4b82849164950cc1aeac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afe17bba9f044b70a833de0d86f64a31"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small',model_max_length=512)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "bMcbTxUNfREI"
      },
      "outputs": [],
      "source": [
        "class QuestionGenerationDataset(Dataset):\n",
        "    def __init__(self, tokenizer, filepath, max_len_inp=512,max_len_out=512):\n",
        "        self.path = filepath\n",
        "\n",
        "        self.passage_column = \"context\"\n",
        "        self.answer = \"answer\"\n",
        "        self.question = \"question\"\n",
        "\n",
        "        # self.data = pd.read_csv(self.path)\n",
        "        self.data = pd.read_parquet(self.path).iloc[:2000,:]\n",
        "        self.max_len_input = max_len_inp\n",
        "        self.max_len_output = max_len_out\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  #squeeze to get rid of the batch dimension\n",
        "        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # convert [batch,dim] to [dim]\n",
        "\n",
        "\n",
        "        labels = copy.deepcopy(target_ids)\n",
        "        labels [labels==0] = -100\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask,\"labels\":labels}\n",
        "\n",
        "    def _build(self):\n",
        "        for rownum,val in tqdm(self.data.iterrows()): # Iterating over the dataframe\n",
        "            passage,answer,target = val[self.passage_column],val[self.answer],val[self.question]\n",
        "\n",
        "            input_ = f\"context: {passage}\" # T5 Input format for question answering tasks\n",
        "            target = f\"question: {str(target)} answer: {answer}\" # Output format we require\n",
        "            # tokenize inputs\n",
        "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "                [input_], max_length=self.max_len_input,padding='max_length',\n",
        "                truncation = True,return_tensors=\"pt\"\n",
        "            )\n",
        "            # tokenize targets\n",
        "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "                [target], max_length=self.max_len_output,padding='max_length',\n",
        "                truncation = True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            self.inputs.append(tokenized_inputs)\n",
        "            self.targets.append(tokenized_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ct6G1jKrlbwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed70249d-facf-4296-a847-1ca14d1b010b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000it [00:07, 260.52it/s]\n",
            "2000it [00:07, 278.86it/s]\n"
          ]
        }
      ],
      "source": [
        "train_path = '/content/drive/MyDrive/train_race.parquet' # change this accordingly\n",
        "validation_path = '/content/drive/MyDrive/validation_race.parquet'\n",
        "train_dataset = QuestionGenerationDataset(t5_tokenizer,train_path)\n",
        "validation_dataset = QuestionGenerationDataset(t5_tokenizer,validation_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "exYklcOnvNak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5df2725-ee41-465f-e316-cbbeb413cca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: Understanding the process of making career choices and managing your career is a basic life skill that everyone should understand. Your career decisions have such a profound effect on all aspects of your life. It's important to have the knowledge and resources needed to make smart, informed decisions. Whether you are looking for a new job, aiming to take the next step at your current job or planning your retirement options, you are making career decisions. Using good resources and the guidance of a career counselor can help you to make those decisions well. Many people mistakenly believe that choosing a career is a one-time event that happens some time in early adulthood. However, career management is actually a life-long process, and we continue to make consequential career choices over the years. When people want to take action in their career, career management and job search are about so much more than writing a good resume. If you learn about and act on the following areas of career management, you'll be rewarded throughout your career. Your interests, abilities, values, personal needs and realities should all be taken into account in any career decision making process. You spend countless hours at work, and it impacts your life in so many ways; it makes sense that you should be fully informed before making such profound decisions. Do you know how many different career choices are available to you? Both The Dictionary of Occupational Titles (American) and The National Occupational Classification (Canadian) list well over 20,000 different job titles. So unless you've actively explored a variety of career options, there's a very good chance that there are great possibilities available to you, and you don't even realize they exist. Match your understanding of yourself with your understanding of possible career options. Once you have developed a good understanding of yourself, you will be able to combine that self-knowledge with your career and labor market research to determine potential careers that are a great fit for you. When you've made a well informed decision, then you're ready to make it happen. Making use of good career guidance and resources will help you to acquire the education, skills, and experience needed to get the job and learn and implement effective job search strategies. Time spent understanding your needs, researching your career options and developing outstanding job search skills, guided by great career resources, is a powerful investment in your future.</s><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "question: Which of the following statements is NOT TRUE according to the passage? answer: You are to make significant decisions without good resources and the guidance of a career adviser.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ],
      "source": [
        "# Data Sample\n",
        "\n",
        "train_sample = train_dataset[10] # thanks to __getitem__\n",
        "decoded_train_input = t5_tokenizer.decode(train_sample['source_ids'])\n",
        "decoded_train_output = t5_tokenizer.decode(train_sample['target_ids'])\n",
        "\n",
        "print(decoded_train_input)\n",
        "print(decoded_train_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgpA1GU9wkgA"
      },
      "source": [
        "# Fine Tuning T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "10-Ap-LnwmeM"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.optim import AdamW\n",
        "import argparse\n",
        "from transformers import (\n",
        "    get_linear_schedule_with_warmup\n",
        "  )\n",
        "\n",
        "class T5Tuner(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,t5model, t5tokenizer,batchsize=4):\n",
        "        super().__init__()\n",
        "        self.model = t5model\n",
        "        self.tokenizer = t5tokenizer\n",
        "        self.batch_size = batchsize\n",
        "\n",
        "    def forward( self, input_ids, attention_mask=None,\n",
        "                decoder_attention_mask=None,\n",
        "                lm_labels=None):\n",
        "\n",
        "         outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            labels=lm_labels,\n",
        "        )\n",
        "\n",
        "         return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            decoder_attention_mask=batch['target_mask'],\n",
        "            lm_labels=batch['labels']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "        self.log('train_loss',loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            decoder_attention_mask=batch['target_mask'],\n",
        "            lm_labels=batch['labels']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "        self.log(\"val_loss\",loss)\n",
        "        return loss\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(train_dataset, batch_size=self.batch_size,\n",
        "                          num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(validation_dataset,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=2)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=3e-4, eps=1e-8)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E5o7b1T3F7W"
      },
      "outputs": [],
      "source": [
        "model = T5Tuner(t5_model,t5_tokenizer)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 3,accelerator=device)\n",
        "\n",
        "trainer.fit(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbD88PJiFapv"
      },
      "outputs": [],
      "source": [
        "# saving the model\n",
        "!mkdir \"t5_tokenizer\"\n",
        "!mkdir \"t5_trained_model\"\n",
        "model.model.save_pretrained('/content/drive/MyDrive/t5_trained_model')\n",
        "t5_tokenizer.save_pretrained('/content/drive/MyDrive/t5_tokenizer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVD6R7j2FWfU"
      },
      "source": [
        "# Inference / Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Trained Model from Drive"
      ],
      "metadata": {
        "id": "4a0ubAQC2MwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "oxE0jOQCFYRq"
      },
      "outputs": [],
      "source": [
        "trained_model_path = '/content/drive/MyDrive/t5_trained_model'\n",
        "trained_tokenizer = '/content/drive/MyDrive/t5_tokenizer'\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "bSAV5DP7GCzn"
      },
      "outputs": [],
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYIpvIQaGSHO"
      },
      "source": [
        "Text Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Yd6K9qdY-Cr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5251ae85-8760-4224-9fe5-73a53fb1d3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context: Holi is considered as one of the most revered and celebrated festivals of India and it is celebrated in almost every part of the country. It is also sometimes called as the “festival of love” as on this day people get to unite together forgetting all resentments and all types of bad feeling towards each other. The great Indian festival lasts for a day and a night, which starts in the evening of Purnima or the Full Moon Day in the month of Falgun. It is celebrated with the name Holika Dahan or Choti Holi on first evening of the festival and the following day is called Holi. In different parts of the country it is known with different names. The vibrancy of colors is something that brings in a lot of positivity in our lives and Holi being the festival of colours is actually a day worth rejoicing. Holi is a famous Hindu festival that is celebrated in every part of India with utmost joy and enthusiasm. The ritual starts by lighting up the bonfire one day before the day of Holi and this process symbolizes the triumph of good over the bad. On the day of Holi people play with colours with their friends and families and in evening they show love and respect to their close ones with Abeer.\n"
          ]
        }
      ],
      "source": [
        "context =\"Holi is considered as one of the most revered and celebrated festivals of India and it is celebrated in almost every part of the country. It is also sometimes called as the “festival of love” as on this day people get to unite together forgetting all resentments and all types of bad feeling towards each other. The great Indian festival lasts for a day and a night, which starts in the evening of Purnima or the Full Moon Day in the month of Falgun. It is celebrated with the name Holika Dahan or Choti Holi on first evening of the festival and the following day is called Holi. In different parts of the country it is known with different names. The vibrancy of colors is something that brings in a lot of positivity in our lives and Holi being the festival of colours is actually a day worth rejoicing. Holi is a famous Hindu festival that is celebrated in every part of India with utmost joy and enthusiasm. The ritual starts by lighting up the bonfire one day before the day of Holi and this process symbolizes the triumph of good over the bad. On the day of Holi people play with colours with their friends and families and in evening they show love and respect to their close ones with Abeer.\"\n",
        "\n",
        "text = \"context: \"+context\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "XmEqkhNfGUVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdf5404-ef46-499a-bfad-3662c980fe3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ],
      "source": [
        "encoding = tokenizer.encode_plus(text,max_length =512,padding='max_length',\n",
        "                                 truncation = True,\n",
        "                                 return_tensors=\"pt\").to(device)\n",
        "print (encoding.keys())\n",
        "input_ids,attention_mask  = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "mcXXoYDqGniS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bda8195-4543-4027-f3e3-c3f4adea29f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question: Are there any other interesting aspects about this article? answer: ['Holi is considered as one of the most revered and celebrated festivals of India']\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "beam_outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_length=72, # How long the generated questions should be\n",
        "    early_stopping=True,\n",
        "    num_beams=5,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "for beam_output in beam_outputs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    print(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yokqUsiu_nHl"
      },
      "source": [
        "# Testing before Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "_67IW4GUCawH"
      },
      "outputs": [],
      "source": [
        "def get_question(sentence,mdl,tknizer):\n",
        "\n",
        "  ''' function to generate questions. Takes a sentence,answer,\n",
        "      model and tokenizer\n",
        "  '''\n",
        "\n",
        "  text = \"context: {}\".format(sentence)\n",
        "  #print (text)\n",
        "  max_len = 256\n",
        "  encoding = tknizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = mdl.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=72)\n",
        "  #print(\"outputs\")\n",
        "  #print(outs)\n",
        "  for beam_output in outs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    #print(sent)\n",
        "\n",
        "  dec = [tknizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "  #print(\"decs\")\n",
        "  #print(dec)\n",
        "\n",
        "  Question = dec[0]\n",
        "  #Question= Question.strip()\n",
        "  #Answer= Answer.strip()\n",
        "  #print(Answer)\n",
        "  index = Question.find(\"answer:\")\n",
        "\n",
        "  # Extract the question and answer based on the position\n",
        "  question = Question[10:index].strip()\n",
        "  answer = Question[index + len(\"answer:\"):].strip()\n",
        "  #print(\"Question1:\", question)\n",
        "  #print(\"Answer1:\", answer)\n",
        "\n",
        "  return  question,answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxQQ3wdnDJ4D",
        "outputId": "d6e0a1c4-fa9e-4c7b-84e6-81090379bcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context:  Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to many fields including large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5] ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods. \n",
            "question:  Are there any other interesting aspects about this article?\n",
            "answer:  [\"ML is known in its application across business problems under the name predictive analytics.\"]\n"
          ]
        }
      ],
      "source": [
        "context = \"Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.Machine learning approaches have been applied to many fields including large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5] ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods. \"\n",
        "\n",
        "print(\"context: \",context)\n",
        "ques,answer = get_question(context,model,tokenizer)\n",
        "print (\"question: \",ques)\n",
        "print (\"answer: \",answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine Tuning on Custom Dataset"
      ],
      "metadata": {
        "id": "thRlRDzO5Tz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "id": "vkeIRxcvfKf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f4195a-1e6a-4192-9bc1-4e462ee5aa1e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/232.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"\"\" Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3]\n",
        "\n",
        "Machine learning approaches have been applied to many fields including large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5] ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\n",
        "\n",
        "The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.[7][8] From a theoretical point of view Probably approximately correct learning provides a framework for describing machine learning. \"\"\""
      ],
      "metadata": {
        "id": "rkD-l1cOxYzX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_into_paragraphs(text):\n",
        "\n",
        "    # Split the text into individual lines\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Initialize an empty list to store paragraphs\n",
        "    paragraphs = []\n",
        "\n",
        "    # Initialize an empty string to store the current paragraph\n",
        "    current_paragraph = ''\n",
        "\n",
        "    # Iterate over each line\n",
        "    for line in lines:\n",
        "        # If the line is empty, consider it as a paragraph break\n",
        "        if not line.strip():\n",
        "            # Append the current paragraph to the list if it's not empty\n",
        "            if current_paragraph.strip():\n",
        "                paragraphs.append(current_paragraph.strip())\n",
        "            # Reset the current paragraph\n",
        "            current_paragraph = ''\n",
        "        else:\n",
        "            # Append the line to the current paragraph with a space\n",
        "            current_paragraph += line.strip() + ' '\n",
        "\n",
        "    # Append the last paragraph if it's not empty\n",
        "    if current_paragraph.strip():\n",
        "        paragraphs.append(current_paragraph.strip())\n",
        "\n",
        "    # Return the list of paragraphs\n",
        "    return paragraphs\n",
        "\n",
        "# Example usage\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y3GTRwIIuj80"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pikepdf\n",
        "from pikepdf import Pdf\n",
        "pdf = Pdf.open('/content/drive/MyDrive/Machine Learning - Tom Mitchell_compressed.pdf')\n",
        "len(pdf.pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4dWvSgd6pfQ",
        "outputId": "d41ab3ed-8884-43ac-e067-27cca7748d1d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (8.12.0)\n",
            "Requirement already satisfied: Pillow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from pikepdf) (10.2.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf) (1.2.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pikepdf) (23.2)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.10/dist-packages (from pikepdf) (4.9.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pikepdf) (1.14.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "KjeSCFb0o2nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498d8cfd-74a8-4fc9-a5de-2f0a565331ef"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filename,  verbose = False):\n",
        "  data  = pd.read_csv(filename, skipinitialspace=True, usecols=['Context','Question','Answer'] )\n",
        "  result_df1  = pd.DataFrame(columns = ['context', 'question','answer'])\n",
        "  result_df1 = data[0:177, : ]\n",
        "  return result_df1"
      ],
      "metadata": {
        "id": "sXzXMQoqudoB"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionGenerationDataset_New(Dataset):\n",
        "    def __init__(self, tokenizer, data, max_len_inp=512,max_len_out=512):\n",
        "        self.passage_column = \"Context\"\n",
        "        self.answer = \"Answer\"\n",
        "        self.question = \"Question\"\n",
        "\n",
        "        # self.data = pd.read_csv(self.path)\n",
        "        self.data = data\n",
        "        self.max_len_input = max_len_inp\n",
        "        self.max_len_output = max_len_out\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  #squeeze to get rid of the batch dimension\n",
        "        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # convert [batch,dim] to [dim]\n",
        "\n",
        "\n",
        "        labels = copy.deepcopy(target_ids)\n",
        "        labels [labels==0] = -100\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask,\"labels\":labels}\n",
        "\n",
        "    def _build(self):\n",
        "        for rownum,val in tqdm(self.data.iterrows()): # Iterating over the dataframe\n",
        "\n",
        "            passage,answer,target = val[self.passage_column],val[self.answer],val[self.question]\n",
        "\n",
        "            input_ = f\"context: {passage}\" # T5 Input format for question answering tasks\n",
        "            target = f\"question: {str(target)} answer: {answer}\" # Output format we require\n",
        "            # tokenize inputs\n",
        "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "                [input_], max_length=self.max_len_input,padding='max_length',\n",
        "                truncation = True,return_tensors=\"pt\"\n",
        "            )\n",
        "            # tokenize targets\n",
        "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "                [target], max_length=self.max_len_output,padding='max_length',\n",
        "                truncation = True,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "            self.inputs.append(tokenized_inputs)\n",
        "            self.targets.append(tokenized_targets)"
      ],
      "metadata": {
        "id": "7qpbCIwZu05F"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset1 = QuestionGenerationDataset_New(t5_tokenizer,df2.sample(frac = 0.7))\n",
        "validation_dataset1 = QuestionGenerationDataset_New(t5_tokenizer,df2.drop(df2.sample(frac = 0.7).index))"
      ],
      "metadata": {
        "id": "2cA_6Ph4vGmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f46dc4-51e7-46c0-d5f5-b89ff9113974"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "124it [00:02, 58.72it/s]\n",
            "53it [00:01, 52.17it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.optim import AdamW\n",
        "import argparse\n",
        "from transformers import (\n",
        "    get_linear_schedule_with_warmup\n",
        "  )\n",
        "\n",
        "class T5Tuner1(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,t5model, t5tokenizer,batchsize=4):\n",
        "        super().__init__()\n",
        "        self.model = t5model\n",
        "        self.tokenizer = t5tokenizer\n",
        "        self.batch_size = batchsize\n",
        "\n",
        "    def forward( self, input_ids, attention_mask=None,\n",
        "                decoder_attention_mask=None,\n",
        "                lm_labels=None):\n",
        "\n",
        "         outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            labels=lm_labels,\n",
        "        )\n",
        "\n",
        "         return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            decoder_attention_mask=batch['target_mask'],\n",
        "            lm_labels=batch['labels']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "        self.log('train_loss',loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            decoder_attention_mask=batch['target_mask'],\n",
        "            lm_labels=batch['labels']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "        self.log(\"val_loss\",loss)\n",
        "        return loss\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(train_dataset1, batch_size=self.batch_size,\n",
        "                          num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(validation_dataset1,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=2)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=3e-4, eps=1e-8)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "Ix8IV4JRvSqF"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_path = '/content/drive/MyDrive/t5_trained_model'\n",
        "trained_tokenizer = '/content/drive/MyDrive/t5_tokenizer'\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "mxUzQmTdwcJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n",
        "tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer)\n",
        "\n",
        "model1 = T5Tuner1(model,tokenizer)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 10,accelerator=device, log_every_n_steps=10)\n",
        "\n",
        "trainer.fit(model1)"
      ],
      "metadata": {
        "id": "OdutTq2XvbqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "#!mkdir \"t5_tokenizer1\"\n",
        "#!mkdir \"t5_trained_model1\"\n",
        "model1.model.save_pretrained('/content/drive/MyDrive/t5_trained_model2')\n",
        "t5_tokenizer.save_pretrained('/content/drive/MyDrive/t5_tokenizer2')"
      ],
      "metadata": {
        "id": "xtp99qcW1MmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fined Tuned with 10 Epochs & saved on this location"
      ],
      "metadata": {
        "id": "DyqkVp0l1vdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.model.save_pretrained('/content/drive/MyDrive/t5_trained_model2')\n",
        "t5_tokenizer.save_pretrained('/content/drive/MyDrive/t5_tokenizer2')"
      ],
      "metadata": {
        "id": "FkqClY8gh1tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "UeUdfbtp4-N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model_path1 = '/content/drive/MyDrive/t5_trained_model2'\n",
        "trained_tokenizer1 = '/content/drive/MyDrive/t5_tokenizer2'\n",
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "SDd7XYO55Ac6"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = T5ForConditionalGeneration.from_pretrained(trained_model_path1)\n",
        "tokenizer1 = T5Tokenizer.from_pretrained(trained_tokenizer1)"
      ],
      "metadata": {
        "id": "qm_cjfgV5KCB"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_question1(sentence,mdl,tknizer):\n",
        "\n",
        "  ''' function to generate questions. Takes a sentence,answer,\n",
        "      model and tokenizer\n",
        "  '''\n",
        "\n",
        "  text = \"context: {}\".format(sentence)\n",
        "  #print (text)\n",
        "  max_len = 256\n",
        "  encoding = tknizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = mdl.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=72)\n",
        "  #print(\"outputs\")\n",
        "  #print(outs)\n",
        "  for beam_output in outs:\n",
        "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    #print(sent)\n",
        "\n",
        "  dec = [tknizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "  #print(\"decs\")\n",
        "  #print(dec)\n",
        "\n",
        "  Question = dec[0]\n",
        "  #Question= Question.strip()\n",
        "  #Answer= Answer.strip()\n",
        "  #print(Answer)\n",
        "  index = Question.find(\"answer:\")\n",
        "\n",
        "  # Extract the question and answer based on the position\n",
        "  question = Question[10:index].strip()\n",
        "  answer = Question[index + len(\"answer:\"):].strip()\n",
        "  #print(\"Question1:\", question)\n",
        "  #print(\"Answer1:\", answer)\n",
        "\n",
        "  return  question,answer"
      ],
      "metadata": {
        "id": "aiN_On2y3r-E"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Model"
      ],
      "metadata": {
        "id": "xB1jYRMOqOne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to many fields including large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5] ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods. The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.[7][8] From a theoretical point of view Probably approximately correct learning provides a framework for describing machine learning.\"\n",
        "print(\"context: \",context)\n",
        "ques,answer = get_question1(context,model1,tokenizer1)\n",
        "print (\"question: \",ques)\n",
        "print (\"answer: \",answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QcY4Sti30s0",
        "outputId": "96e10d81-ccbe-452a-f7f9-220bd6a0b5f3"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context:  Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Recently, generative artificial neural networks have been able to surpass many previous approaches in performance.[2][3] Machine learning approaches have been applied to many fields including large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly to develop algorithms to perform the needed tasks.[4][5] ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods. The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.[7][8] From a theoretical point of view Probably approximately correct learning provides a framework for describing machine learning.\n",
            "question:  What are the advantages of machine learning in the field of study in artificial intelligence?\n",
            "answer:  Machine learning (ML) is known in its application across business problems under the name predictive analytics. It has been applied to many fields including large language models, computer vision, speech recognition, email filtering, agriculture, and medicine, where it is too costly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_into_paragraphs(text, num_paragraphs):\n",
        "    # Split the text into paragraphs based on the desired number\n",
        "    words = text.split()\n",
        "    words_per_paragraph = len(words) // num_paragraphs\n",
        "\n",
        "    paragraphs = []\n",
        "    start_index = 0\n",
        "    for _ in range(num_paragraphs - 1):\n",
        "        end_index = start_index + words_per_paragraph\n",
        "        paragraph = \" \".join(words[start_index:end_index])\n",
        "        paragraphs.append(paragraph)\n",
        "        start_index = end_index\n",
        "\n",
        "    # Add the remaining words as the last paragraph\n",
        "    last_paragraph = \" \".join(words[start_index:])\n",
        "    paragraphs.append(last_paragraph)\n",
        "\n",
        "    return paragraphs\n"
      ],
      "metadata": {
        "id": "jDykKBK6hNDq"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Question & Answer Function without Similarity Check"
      ],
      "metadata": {
        "id": "voUklkQxAvil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import math\n",
        "\n",
        "def qa_func(start_page: int, end_page: int, num_qa: int):\n",
        "  #qa_dict=dict.fromkeys('Question','Answer')\n",
        "  qa_dict={}\n",
        "  num_qa_per_pg = math.ceil(num_qa/(end_page-start_page+1))\n",
        "  if (num_qa_per_pg>5): #5 is hyperparamer which means it will generate 5 questions per page\n",
        "    print('Enter less number of questions')\n",
        "  else:\n",
        "\n",
        "      pdf_file_path = \"/content/drive/MyDrive/Machine Learning - Tom Mitchell_compressed.pdf\"\n",
        "      with open(pdf_file_path, \"rb\") as file:\n",
        "          pdf_reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "          # Find the start and end page numbers of the desired chapter from the index\n",
        "          # start_page = 10  # Replace with the actual start page number of the chapter\n",
        "          # end_page = 20    # Replace with the actual end page number of the chapter\n",
        "\n",
        "          # Extract pages of the desired chapter\n",
        "          extracted_pages = []\n",
        "          count=0\n",
        "          for page_num in range(start_page, end_page+1):\n",
        "              page = pdf_reader.pages[page_num].extract_text()\n",
        "              #print(page_num)\n",
        "\n",
        "              paragraphs = divide_into_paragraphs(page, num_qa_per_pg)\n",
        "              for i, paragraph in enumerate(paragraphs):\n",
        "\n",
        "                if (count<num_qa):\n",
        "                  ques,answer = get_question1(paragraph,model1,tokenizer1)\n",
        "                  print(paragraph)\n",
        "                  qa_dict[ques] = answer\n",
        "                  '''print (\"question: \",ques)\n",
        "                  print (\"answer: \",answer)'''\n",
        "                  count=count+1\n",
        "                else:\n",
        "                  #print (\"qa_dict: \",qa_dict)\n",
        "                  break\n",
        "  return qa_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBi21y2CiEg1",
        "outputId": "12e39a49-fd7a-443e-9e6e-e3167aedee34"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling qa_func"
      ],
      "metadata": {
        "id": "k9sdaptr73H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict={}\n",
        "my_dict=qa_func(14,15,2)\n",
        "print(my_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnk5n0mV71Tp",
        "outputId": "1be0b5e7-2070-41a6-f297-950e0c996302"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER 1 INTRODUCITON 3 0 Learning to recognize spoken words. All of the most successful speech recognition systems employ machine learning in some form. For example, the SPHINX system (e.g., Lee 1989) learns speaker-specific strategies for recognizing the primitive sounds (phonemes) and words from the observed speech signal. Neural network learning methods (e.g., Waibel et al. 1989) and methods for learning hidden Markov models (e.g., Lee 1989) are effective for automatically customizing to,individual speakers, vocabularies, microphone characteristics, background noise, etc. Similar techniques have potential applications in many signal-interpretation problems. 0 Learning to drive an autonomous vehicle. Machine learning methods have been used to train computer-controlled vehicles to steer correctly when driving on a variety of road types. For example, the ALVINN system (Pomerleau 1989) has used its learned strategies to drive unassisted at 70 miles per hour for 90 miles on public highways among other cars. Similar techniques have possible applications in many sensor-based control problems. 0 Learning to classify new astronomical structures. Machine learning methods have been applied to a variety of large databases to learn general regularities implicit in the data. For example, decision tree learning algorithms have been used by NASA to learn how to classify celestial objects from the second Palomar Observatory Sky Survey (Fayyad et al. 1995). This system is now used to automatically classify all objects in the Sky Survey, which consists of three terrabytes of image data. 0 Learning to play world-class backgammon. The most successful computer programs for playing games such as backgammon are based on machiie learning algorithms. For example, the world's top computer program for backgammon, TD-GAMMON (Tesauro 1992, 1995). learned its strategy by playing over one million practice games against itself. It now plays at a level competitive with the human world champion. Similar techniques have applications in many practical problems where very large search spaces must be examined efficiently. TABLE 1.1 Some successful applications of machiie learning. three features: the class of tasks, the measure of performance to be improved, and the source of experience. A checkers learning problem: Task T: playing checkers 0 Performance measure P: percent of games won against opponents Training experience E: playing practice games against itself We can specify many learning problems in this fashion, such as learning to recognize handwritten words, or learning to drive a robotic automobile au- tonomously. A handwriting recognition learning problem: 0 Task T: recognizing and classifying handwritten words within images 0 Performance measure P: percent of words correctly classified\n",
            "4 MACHINE LEARNING Artificial intelligence Learning symbolic representations of concepts. Machine learning as a search problem. Learning as an approach to improving problem solving. Using prior knowledge together with training data to guide learning. 0 Bayesian methods Bayes' theorem as the basis for calculating probabilities of hypotheses. The naive Bayes classifier. Algorithms for estimating values of unobserved variables. 0 Computational complexity theory Theoretical bounds on the inherent complexity of different learning tasks, measured in terms of the computational effort, number of training examples, number of mistakes, etc. required in order to learn. Control theory Procedures that learn to control processes in order to optimize predefined objectives and that learn to predict the next state of the process they are controlling. 0 Information theory Measures of entropy and information content. Minimum description length approaches to learning. Optimal codes and their relationship to optimal training sequences for encoding a hypothesis. Philosophy Occam's razor, suggesting that the simplest hypothesis is the best. Analysis of the justification for generalizing beyond observed data. 0 Psychology and neurobiology The power law of practice, which states that over a very broad range of learning problems, people's response time improves with practice according to a power law. Neurobiological studies motivating artificial neural network models of learning. 0 Statistics Characterization of errors (e.g., bias and variance) that occur when estimating the accuracy of a hypothesis based on a limited sample of data. Confidence intervals, statistical tests. TABLE 1.2 Some disciplines and examples of their influence on machine learning. 0 Training experience E: a database of handwritten words with given classi- fications A robot driving learning problem: 0 Task T: driving on public four-lane highways using vision sensors 0 Performance measure P: average distance traveled before an error (as judged by human overseer) 0 Training experience E: a sequence of images and steering commands record- ed while observing a human driver Our definition of learning is broad enough to include most tasks that we would conventionally call \"learning\" tasks, as we use the word in everyday lan- guage. It is also broad enough to encompass computer programs that improve from experience in quite straightforward ways. For example, a database system\n",
            "{'What are the advantages of machine learning in speech recognition systems?': 'Machine learning methods have been used to train computer-controlled vehicles to steer correctly when driving on a variety of road types. These techniques have potential applications in signal-interpretation problems.', 'How does the Computational complexity theory process handle the inherent complexity of different learning tasks?': \"Optimal codes and their relationship to optimal training sequences for encoding a hypothesis are used to optimize predefined objectives and predict the next state of the process they are controlling. Occam's razor suggests that the simplest\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final Question & Answer Function with Similarity Checking Mechanism\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UJd9g89hL31K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "import PyPDF2\n",
        "import math\n",
        "import re\n",
        "\n",
        "def qa_func(start_page: int, end_page: int, num_qa: int):\n",
        "  #qa_dict=dict.fromkeys('Question','Answer')\n",
        "  qa_dict={}\n",
        "  figure_regex = r\"\\b(Fig(?:ure)?\\.?\\s\\d+)\\b\"\n",
        "  table_regex = r\"\\b(Table\\s\\d+)\\b\"\n",
        "  num_qa_per_pg = math.ceil(num_qa/(end_page-start_page+1))\n",
        "  if (num_qa_per_pg>5): #5 is hyperparamer which means it will generate 5 questions per page\n",
        "    print('Enter less number of questions')\n",
        "  else:\n",
        "\n",
        "      pdf_file_path = \"/content/drive/MyDrive/Machine Learning - Tom Mitchell_compressed.pdf\"\n",
        "      with open(pdf_file_path, \"rb\") as file:\n",
        "          pdf_reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "          # Find the start and end page numbers of the desired chapter from the index\n",
        "          # start_page = 10  # Replace with the actual start page number of the chapter\n",
        "          # end_page = 20    # Replace with the actual end page number of the chapter\n",
        "\n",
        "          # Extract pages of the desired chapter\n",
        "          extracted_pages = []\n",
        "          count=0\n",
        "          for page_num in range(start_page, end_page+1):\n",
        "              page = pdf_reader.pages[page_num].extract_text()\n",
        "              print(page_num)\n",
        "\n",
        "              # Remove figures, tables, author names, and titles\n",
        "\n",
        "              page = re.sub(figure_regex, \"\", page, flags=re.IGNORECASE)\n",
        "\n",
        "              page = re.sub(table_regex, \"\", page, flags=re.IGNORECASE)\n",
        "\n",
        "              paragraphs = divide_into_paragraphs(page, num_qa_per_pg)\n",
        "              for i, paragraph in enumerate(paragraphs):\n",
        "                #print(i)\n",
        "\n",
        "                if (count<num_qa):\n",
        "                  print(count)\n",
        "                  ques,answer = get_question1(paragraph,model1,tokenizer1)\n",
        "                  print(ques)\n",
        "                  #if(len(qa_dict) > 0):\n",
        "                  if(process_question(ques,qa_dict.keys())==\" \"):\n",
        "                    qa_dict[ques] = answer\n",
        "                    count=count+1\n",
        "                else:\n",
        "                  break\n",
        "  return qa_dict"
      ],
      "metadata": {
        "id": "c0XDfA5rLHtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85f1b15-b9be-41c1-81ea-3a46c0a4b6eb"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict={}\n",
        "my_dict=qa_func(15,20,2)\n",
        "print(my_dict)"
      ],
      "metadata": {
        "id": "yKhtbSYMDxT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question_Similarity_Implementation"
      ],
      "metadata": {
        "id": "5N4wTeTTLD0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = my_dict.keys()\n",
        "print(len(x))\n",
        "for i in x:\n",
        "  print(i)\n",
        "#print(x)\n",
        "y = my_dict.items()\n",
        "print(y)#Full list\n",
        "z = my_dict.values()\n",
        "print(z)"
      ],
      "metadata": {
        "id": "fzRqKqsQIwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aeb908f-da96-4062-84c2-ba46daa6a1cc"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "What are the advantages of machine learning in speech recognition systems?\n",
            "How does the Computational complexity theory process handle the inherent complexity of different learning tasks?\n",
            "dict_items([('What are the advantages of machine learning in speech recognition systems?', 'Machine learning methods have been used to train computer-controlled vehicles to steer correctly when driving on a variety of road types. These techniques have potential applications in signal-interpretation problems.'), ('How does the Computational complexity theory process handle the inherent complexity of different learning tasks?', \"Optimal codes and their relationship to optimal training sequences for encoding a hypothesis are used to optimize predefined objectives and predict the next state of the process they are controlling. Occam's razor suggests that the simplest\")])\n",
            "dict_values(['Machine learning methods have been used to train computer-controlled vehicles to steer correctly when driving on a variety of road types. These techniques have potential applications in signal-interpretation problems.', \"Optimal codes and their relationship to optimal training sequences for encoding a hypothesis are used to optimize predefined objectives and predict the next state of the process they are controlling. Occam's razor suggests that the simplest\"])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT__8LokCDfE",
        "outputId": "c1d04967-2bcd-4bfc-c620-172d471123af"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class STSBertModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(STSBertModel, self).__init__()\n",
        "\n",
        "        word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=128)\n",
        "        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "        self.sts_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "    def forward(self, input_data):\n",
        "\n",
        "        output = self.sts_model(input_data)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "gXwlL27QDplW"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing S Bert Model"
      ],
      "metadata": {
        "id": "QopPM5c-9DHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers==2.2.1\n",
        "import joblib\n",
        "trained_model = joblib.load('/content/drive/MyDrive/Copy of Sbert_Model_1')"
      ],
      "metadata": {
        "id": "qxwGOVx-9Cd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install sentence-transformers\n",
        "!pip install transformers\n",
        "!pip install torchmetrics.functional\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "from transformers import BertTokenizer\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "G6fxUKFNP-CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict test data\n",
        "def predict_sts(texts):\n",
        "\n",
        "  trained_model .to('cpu')\n",
        "  trained_model.eval()\n",
        "  test_input = tokenizer(texts, padding='max_length', max_length = 128, truncation=True, return_tensors=\"pt\")\n",
        "  test_input['input_ids'] = test_input['input_ids']\n",
        "  test_input['attention_mask'] = test_input['attention_mask']\n",
        "  del test_input['token_type_ids']\n",
        "\n",
        "  test_output = trained_model(test_input)['sentence_embedding']\n",
        "  sim = torch.nn.functional.cosine_similarity(test_output[0], test_output[1], dim=0).item()\n",
        "\n",
        "  return sim"
      ],
      "metadata": {
        "id": "GNgWF800D4ZQ"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question(question,questions):\n",
        "  similarity = False\n",
        "  compare_questions = []\n",
        "  similar_question = \" \"\n",
        "  if(len(question)>0):\n",
        "    for value in questions:\n",
        "      if (similarity == False):\n",
        "        compare_questions.append(question)\n",
        "        #print('Q',question)\n",
        "        compare_questions.append(value)\n",
        "        #print('V',value)\n",
        "        if predict_sts(compare_questions) > 0.8 :\n",
        "          similarity = True\n",
        "          similar_question = value\n",
        "        compare_questions.clear()\n",
        "  return similar_question\n"
      ],
      "metadata": {
        "id": "rQ9f9xu8EIQH"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_answer(answer,answers):\n",
        "  similar_answer = False\n",
        "  compare_answers = []\n",
        "  for value in answers:\n",
        "    if (similarity == False):\n",
        "      compare_answers.add(answer)\n",
        "      compare_answers.add(value)\n",
        "      if predict_sts(compare_answers) > 0.7:\n",
        "        similar_answer = True\n",
        "      compare_answers.clear()\n",
        "  return similar_answer"
      ],
      "metadata": {
        "id": "zIrIzpk6EXd0"
      },
      "execution_count": 128,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06adce485b0e49699cf6ab7ee480daf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fa92abd28534546831e30f92c0f8ff5",
              "IPY_MODEL_1c08e0afafff404dbb7b42160c58d0b2",
              "IPY_MODEL_5e70a35f261640f9b7dc4facf987916f"
            ],
            "layout": "IPY_MODEL_d76c6eba3a3b41afb7545005404aa5ce"
          }
        },
        "8fa92abd28534546831e30f92c0f8ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a543a44b457d4df28b73ae2d80a9b4cb",
            "placeholder": "​",
            "style": "IPY_MODEL_2d0ba6d8771049f8bbcb9060a55848d8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1c08e0afafff404dbb7b42160c58d0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8880954aa2844ee989501038cae969a",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_244adbdd138c496a8412417d189b9c41",
            "value": 2324
          }
        },
        "5e70a35f261640f9b7dc4facf987916f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354124fe2c694a3bb834cddf31b6ca68",
            "placeholder": "​",
            "style": "IPY_MODEL_3e944c4debff46a2b98ee4546e996b1c",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 106kB/s]"
          }
        },
        "d76c6eba3a3b41afb7545005404aa5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a543a44b457d4df28b73ae2d80a9b4cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d0ba6d8771049f8bbcb9060a55848d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8880954aa2844ee989501038cae969a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244adbdd138c496a8412417d189b9c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "354124fe2c694a3bb834cddf31b6ca68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e944c4debff46a2b98ee4546e996b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c407eb69e32a4414809e458a1a7d6b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a14b4fb73e148d29f3f836707f1cd30",
              "IPY_MODEL_272f8d36b5f54b34b28a55aff4f77213",
              "IPY_MODEL_9c7ce581b23a43df86110a9ead75e441"
            ],
            "layout": "IPY_MODEL_3c9dcc13424942eb99147ce99ec0ff29"
          }
        },
        "3a14b4fb73e148d29f3f836707f1cd30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05d561390b81440991bcd2c75af1f5cd",
            "placeholder": "​",
            "style": "IPY_MODEL_a047c26c75ad4027bea05ea2025be993",
            "value": "spiece.model: 100%"
          }
        },
        "272f8d36b5f54b34b28a55aff4f77213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bd30769bfeb4dc5a26dfabef56bdd41",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_077d0ea97f504584b9664ca1b6e83626",
            "value": 791656
          }
        },
        "9c7ce581b23a43df86110a9ead75e441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748e07caa91d4fdd903db0fb8d9c1d59",
            "placeholder": "​",
            "style": "IPY_MODEL_630d98829b8349ef95b656aa24d51bca",
            "value": " 792k/792k [00:00&lt;00:00, 6.59MB/s]"
          }
        },
        "3c9dcc13424942eb99147ce99ec0ff29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d561390b81440991bcd2c75af1f5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a047c26c75ad4027bea05ea2025be993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bd30769bfeb4dc5a26dfabef56bdd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077d0ea97f504584b9664ca1b6e83626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "748e07caa91d4fdd903db0fb8d9c1d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630d98829b8349ef95b656aa24d51bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36df9018f5d74de18638b9b654067a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d0b6b3bee534a5d9cdfb8c725e12ef1",
              "IPY_MODEL_7d48ac0b9571478894537b65417b3e77",
              "IPY_MODEL_270ff8167ce54072b856be7582c36399"
            ],
            "layout": "IPY_MODEL_5cda07d095e34acea382d8b93fac54a6"
          }
        },
        "8d0b6b3bee534a5d9cdfb8c725e12ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_734da418a67647f8bf6b4bd68177db27",
            "placeholder": "​",
            "style": "IPY_MODEL_5e444fc946e243168b37c1eaf2c2a7c8",
            "value": "tokenizer.json: 100%"
          }
        },
        "7d48ac0b9571478894537b65417b3e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8419dde4134681b1b40ac365229860",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f36897f3feb4e939278dd912ec485df",
            "value": 1389353
          }
        },
        "270ff8167ce54072b856be7582c36399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2960399a1f54ea88c18f2b57bdff101",
            "placeholder": "​",
            "style": "IPY_MODEL_666b3246cc18495984edc8d1a9b44cbe",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 22.0MB/s]"
          }
        },
        "5cda07d095e34acea382d8b93fac54a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734da418a67647f8bf6b4bd68177db27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e444fc946e243168b37c1eaf2c2a7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8419dde4134681b1b40ac365229860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f36897f3feb4e939278dd912ec485df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2960399a1f54ea88c18f2b57bdff101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666b3246cc18495984edc8d1a9b44cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f63f11d4689440f695b267f0675714aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb803429d58c4b288dfd5c294dc5d82e",
              "IPY_MODEL_850fcea279574cf3b40598020f9221cc",
              "IPY_MODEL_b58ea7e273814338980a5e52944e90fb"
            ],
            "layout": "IPY_MODEL_076cdb545c3a4027a3ae2b648508854e"
          }
        },
        "bb803429d58c4b288dfd5c294dc5d82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5d5bbf6d9549889bcd3ee3d2b28b90",
            "placeholder": "​",
            "style": "IPY_MODEL_6bfbe3d10dd544628ee2810c69edb9e2",
            "value": "config.json: 100%"
          }
        },
        "850fcea279574cf3b40598020f9221cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53a404631444bc195fd82c1c2f11f06",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57246cf8e0294111b923ed957a728061",
            "value": 1206
          }
        },
        "b58ea7e273814338980a5e52944e90fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_925ac27bf80041c48359b2ff9f0259ea",
            "placeholder": "​",
            "style": "IPY_MODEL_72118739cb6b40d5b06762c59c7806a6",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 75.8kB/s]"
          }
        },
        "076cdb545c3a4027a3ae2b648508854e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5d5bbf6d9549889bcd3ee3d2b28b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfbe3d10dd544628ee2810c69edb9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53a404631444bc195fd82c1c2f11f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57246cf8e0294111b923ed957a728061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "925ac27bf80041c48359b2ff9f0259ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72118739cb6b40d5b06762c59c7806a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "773adce8b8ed4b82849164950cc1aeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92c7622eee1349fea36e757f779b56bf",
              "IPY_MODEL_631946a44fb449b8a00f5fa745375e68",
              "IPY_MODEL_7de536c8889143d88e608f84ab8bdebd"
            ],
            "layout": "IPY_MODEL_97c0bf0a859243bf8a14a879429140d7"
          }
        },
        "92c7622eee1349fea36e757f779b56bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a58f99e8186f44edad8bb447364b624a",
            "placeholder": "​",
            "style": "IPY_MODEL_c54cdcc1a6544d6083191880ce321d52",
            "value": "model.safetensors: 100%"
          }
        },
        "631946a44fb449b8a00f5fa745375e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06d70c31a2ba458e9973acc02755f7af",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ff3c43015d944329a47bb65beff4b94",
            "value": 242043056
          }
        },
        "7de536c8889143d88e608f84ab8bdebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0533193bb941f78d7f54884c86e285",
            "placeholder": "​",
            "style": "IPY_MODEL_79705a8967de4fc5af5c9cb703afdc3a",
            "value": " 242M/242M [00:02&lt;00:00, 49.5MB/s]"
          }
        },
        "97c0bf0a859243bf8a14a879429140d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58f99e8186f44edad8bb447364b624a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c54cdcc1a6544d6083191880ce321d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d70c31a2ba458e9973acc02755f7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff3c43015d944329a47bb65beff4b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c0533193bb941f78d7f54884c86e285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79705a8967de4fc5af5c9cb703afdc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afe17bba9f044b70a833de0d86f64a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09d70d6bf7894e8aac253007737cedcb",
              "IPY_MODEL_0e9b47eb6f394dc98984408112605222",
              "IPY_MODEL_814975cee07645fabaad51c19734e654"
            ],
            "layout": "IPY_MODEL_5e7a53a62687491db7334d225b3f9855"
          }
        },
        "09d70d6bf7894e8aac253007737cedcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea08997b1cd4c8ab016709896cdb1ef",
            "placeholder": "​",
            "style": "IPY_MODEL_0c122d7d3c114fa48a3e16a35fa8a3e3",
            "value": "generation_config.json: 100%"
          }
        },
        "0e9b47eb6f394dc98984408112605222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2a37aa1cd14e1bb5a4e18b7380aa83",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20cf12072faf4cbb8a681f7b96547835",
            "value": 147
          }
        },
        "814975cee07645fabaad51c19734e654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed91704ad46e41b18154ec8a10d15a50",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b23703f56b4bb5a452ebc226fc4dd1",
            "value": " 147/147 [00:00&lt;00:00, 9.52kB/s]"
          }
        },
        "5e7a53a62687491db7334d225b3f9855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aea08997b1cd4c8ab016709896cdb1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c122d7d3c114fa48a3e16a35fa8a3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a2a37aa1cd14e1bb5a4e18b7380aa83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cf12072faf4cbb8a681f7b96547835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed91704ad46e41b18154ec8a10d15a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b23703f56b4bb5a452ebc226fc4dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}