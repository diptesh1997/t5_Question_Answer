{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:38:09.451649Z",
     "start_time": "2023-06-28T00:37:46.832209Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --quiet  datasets #to access race dataset\n",
    "!pip install --quiet pyarrow   #to deal with parquet files for saving dataset if required\n",
    "!pip install --quiet  tqdm     #for progress bars\n",
    "!pip install --quiet transformers # for t5 model\n",
    "!pip install --quiet tokenizers  #tokenizers from HuggingFace\n",
    "!pip install --quiet sentencepiece #subword tokenizer used by T5\n",
    "!pip install --quiet pytorch-lightning # pytorch wrapper\n",
    "!pip install --quiet torchtext # text utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pprint import pprint\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:38:09.455059Z",
     "start_time": "2023-06-28T00:38:09.453174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "device  = 'cuda' if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:38:09.460096Z",
     "start_time": "2023-06-28T00:38:09.457288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pd.options.display.max_rows , pd.options.display.max_columns  = 100,100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:38:09.464534Z",
     "start_time": "2023-06-28T00:38:09.463040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def create_pandas_dataset(data,\n",
    "                          answer_threshold=512,\n",
    "                          verbose = False):\n",
    "\n",
    "  ''' Create a Pandas Dataframe from hugging face dataset.\n",
    "  Params:\n",
    "        answer_threshold: Only consider those Question Answer pairs where the Answer is short.\n",
    "  '''\n",
    "  count_long ,count_short = 0 , 0\n",
    "  result_df  = pd.DataFrame(columns = ['context', 'question','answer'])\n",
    "  for index,val in enumerate(tqdm(data)):\n",
    "      passage = val['article']\n",
    "      question = val['question']\n",
    "      ans = val['answer']\n",
    "      answer = val['options'][ord(ans)-65]\n",
    "      no_of_words = len(answer.split())\n",
    "      if no_of_words >= answer_threshold:\n",
    "          count_long = count_long + 1\n",
    "          continue\n",
    "      else:\n",
    "          result_df.loc[count_short] = [passage] +[question] + [answer]\n",
    "          count_short = count_short + 1\n",
    "  if verbose:\n",
    "    return (result_df,\n",
    "            count_long,\n",
    "            count_short)\n",
    "  else:\n",
    "    return result_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:38:09.472145Z",
     "start_time": "2023-06-28T00:38:09.469820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset race (/Users/dipteshmukherjee/.cache/huggingface/datasets/race/high/0.1.0/5839ff74a429622f5f20cca69c5fcf0e87ac6d5fd2777c42b948000684829f7b)\n",
      "Found cached dataset race (/Users/dipteshmukherjee/.cache/huggingface/datasets/race/high/0.1.0/5839ff74a429622f5f20cca69c5fcf0e87ac6d5fd2777c42b948000684829f7b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train Samples:62445 , Total Validation Samples:3451\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('race','high', split='train')\n",
    "valid_dataset = load_dataset('race', 'high', split='validation')\n",
    "print(f\"Total Train Samples:{len(train_dataset)} , Total Validation Samples:{len(valid_dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:38:15.370464Z",
     "start_time": "2023-06-28T00:38:09.474787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62445/62445 [02:54<00:00, 357.19it/s]\n",
      "100%|██████████| 3451/3451 [00:02<00:00, 1174.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total Train Samples:(62445, 3) , Total Validation Samples:(3451, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train , df_validation = create_pandas_dataset(train_dataset) , create_pandas_dataset(valid_dataset)\n",
    "print(f\"\\n Total Train Samples:{df_train.shape} , Total Validation Samples:{df_validation.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:41:13.187246Z",
     "start_time": "2023-06-28T00:38:15.391087Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Saving data for future use\n",
    "df_train.to_parquet('train_race.parquet')\n",
    "df_validation.to_parquet('validation_race.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:41:13.841021Z",
     "start_time": "2023-06-28T00:41:13.190524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 context  \\\n0      Last week I talked with some of my students ab...   \n1      Last week I talked with some of my students ab...   \n2      Last week I talked with some of my students ab...   \n3      Last week I talked with some of my students ab...   \n4      YUZHOU, HENAN -An accident in a central China ...   \n...                                                  ...   \n62440  What if I took that big jump on my bike?What's...   \n62441  What if I took that big jump on my bike?What's...   \n62442  What if I took that big jump on my bike?What's...   \n62443  When officials in Richmond, B. C., Canada, tol...   \n62444  When officials in Richmond, B. C., Canada, tol...   \n\n                                                question  \\\n0      We can know from the passage that the author w...   \n1      Many graduates today turn to cosmetic surgery ...   \n2      According to the passage, the author believes ...   \n3              Which' s the best title for the passage?.   \n4         What could be the best title for this passage?   \n...                                                  ...   \n62440  According to the text,the teenager who explore...   \n62441  What does the writer want to tell us by taking...   \n62442        What may the text discuss in the next part?   \n62443  Stephen Covey was doubtful at first because he...   \n62444  In covey's first opinion, people in Richmond, ...   \n\n                                                  answer  \n0                                                teacher  \n1            get an advantage over others in job-hunting  \n2      media are to blame for misleading young people...  \n3        Young Graduates Look to Surgery for Better Jobs  \n4                  A Coal Mine Accident in Central China  \n...                                                  ...  \n62440                       have advantages over others.  \n62441  Mice also experience a period to explore the w...  \n62442          What really goes on in the teenage brain.  \n62443  youth crime was too complex for ordinary citiz...  \n62444            had no ability to make great difference  \n\n[62445 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Last week I talked with some of my students ab...</td>\n      <td>We can know from the passage that the author w...</td>\n      <td>teacher</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Last week I talked with some of my students ab...</td>\n      <td>Many graduates today turn to cosmetic surgery ...</td>\n      <td>get an advantage over others in job-hunting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Last week I talked with some of my students ab...</td>\n      <td>According to the passage, the author believes ...</td>\n      <td>media are to blame for misleading young people...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Last week I talked with some of my students ab...</td>\n      <td>Which' s the best title for the passage?.</td>\n      <td>Young Graduates Look to Surgery for Better Jobs</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n      <td>What could be the best title for this passage?</td>\n      <td>A Coal Mine Accident in Central China</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>62440</th>\n      <td>What if I took that big jump on my bike?What's...</td>\n      <td>According to the text,the teenager who explore...</td>\n      <td>have advantages over others.</td>\n    </tr>\n    <tr>\n      <th>62441</th>\n      <td>What if I took that big jump on my bike?What's...</td>\n      <td>What does the writer want to tell us by taking...</td>\n      <td>Mice also experience a period to explore the w...</td>\n    </tr>\n    <tr>\n      <th>62442</th>\n      <td>What if I took that big jump on my bike?What's...</td>\n      <td>What may the text discuss in the next part?</td>\n      <td>What really goes on in the teenage brain.</td>\n    </tr>\n    <tr>\n      <th>62443</th>\n      <td>When officials in Richmond, B. C., Canada, tol...</td>\n      <td>Stephen Covey was doubtful at first because he...</td>\n      <td>youth crime was too complex for ordinary citiz...</td>\n    </tr>\n    <tr>\n      <th>62444</th>\n      <td>When officials in Richmond, B. C., Canada, tol...</td>\n      <td>In covey's first opinion, people in Richmond, ...</td>\n      <td>had no ability to make great difference</td>\n    </tr>\n  </tbody>\n</table>\n<p>62445 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_parquet('train_race.parquet', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:41:16.062222Z",
     "start_time": "2023-06-28T00:41:13.825137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Creating a Pytorch DataSet for T5 Training and Validation\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:41:17.673576Z",
     "start_time": "2023-06-28T00:41:16.058603Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db1f6cd60a64480292ed6fb3b09f0b8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small',model_max_length=512)\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:42:15.651589Z",
     "start_time": "2023-06-28T00:41:17.671784Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class QuestionGenerationDataset(Dataset):\n",
    "    def __init__(self, tokenizer, filepath, max_len_inp=512,max_len_out=512):\n",
    "        self.path = filepath\n",
    "\n",
    "        self.passage_column = \"context\"\n",
    "        self.answer = \"answer\"\n",
    "        self.question = \"question\"\n",
    "\n",
    "        # self.data = pd.read_csv(self.path)\n",
    "        self.data = pd.read_parquet(self.path).iloc[:2000,:]\n",
    "        self.max_len_input = max_len_inp\n",
    "        self.max_len_output = max_len_out\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        self._build()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  #squeeze to get rid of the batch dimension\n",
    "        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # convert [batch,dim] to [dim]\n",
    "\n",
    "\n",
    "        labels = copy.deepcopy(target_ids)\n",
    "        labels [labels==0] = -100\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask,\"labels\":labels}\n",
    "\n",
    "    def _build(self):\n",
    "        for rownum,val in tqdm(self.data.iterrows()): # Iterating over the dataframe\n",
    "            passage,answer,target = val[self.passage_column],val[self.answer],val[self.question]\n",
    "\n",
    "            input_ = f\"context: {passage}\" # T5 Input format for question answering tasks\n",
    "            target = f\"question: {str(target)} answer: {answer}\" # Output format we require\n",
    "            # tokenize inputs\n",
    "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "                [input_], max_length=self.max_len_input,padding='max_length',\n",
    "                truncation = True,return_tensors=\"pt\"\n",
    "            )\n",
    "            # tokenize targets\n",
    "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "                [target], max_length=self.max_len_output,padding='max_length',\n",
    "                truncation = True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            self.inputs.append(tokenized_inputs)\n",
    "            self.targets.append(tokenized_targets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:42:15.663261Z",
     "start_time": "2023-06-28T00:42:15.653742Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:03, 535.83it/s]\n",
      "2000it [00:03, 534.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = 'train_race.parquet' # change this accordingly\n",
    "validation_path = 'validation_race.parquet'\n",
    "train_dataset = QuestionGenerationDataset(t5_tokenizer,train_path)\n",
    "validation_dataset = QuestionGenerationDataset(t5_tokenizer,validation_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:42:23.413716Z",
     "start_time": "2023-06-28T00:42:15.667921Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Understanding the process of making career choices and managing your career is a basic life skill that everyone should understand. Your career decisions have such a profound effect on all aspects of your life. It's important to have the knowledge and resources needed to make smart, informed decisions. Whether you are looking for a new job, aiming to take the next step at your current job or planning your retirement options, you are making career decisions. Using good resources and the guidance of a career counselor can help you to make those decisions well. Many people mistakenly believe that choosing a career is a one-time event that happens some time in early adulthood. However, career management is actually a life-long process, and we continue to make consequential career choices over the years. When people want to take action in their career, career management and job search are about so much more than writing a good resume. If you learn about and act on the following areas of career management, you'll be rewarded throughout your career. Your interests, abilities, values, personal needs and realities should all be taken into account in any career decision making process. You spend countless hours at work, and it impacts your life in so many ways; it makes sense that you should be fully informed before making such profound decisions. Do you know how many different career choices are available to you? Both The Dictionary of Occupational Titles (American) and The National Occupational Classification (Canadian) list well over 20,000 different job titles. So unless you've actively explored a variety of career options, there's a very good chance that there are great possibilities available to you, and you don't even realize they exist. Match your understanding of yourself with your understanding of possible career options. Once you have developed a good understanding of yourself, you will be able to combine that self-knowledge with your career and labor market research to determine potential careers that are a great fit for you. When you've made a well informed decision, then you're ready to make it happen. Making use of good career guidance and resources will help you to acquire the education, skills, and experience needed to get the job and learn and implement effective job search strategies. Time spent understanding your needs, researching your career options and developing outstanding job search skills, guided by great career resources, is a powerful investment in your future.</s><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "question: Which of the following statements is NOT TRUE according to the passage? answer: You are to make significant decisions without good resources and the guidance of a career adviser.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# Data Sample\n",
    "\n",
    "train_sample = train_dataset[10] # thanks to __getitem__\n",
    "decoded_train_input = t5_tokenizer.decode(train_sample['source_ids'])\n",
    "decoded_train_output = t5_tokenizer.decode(train_sample['target_ids'])\n",
    "\n",
    "print(decoded_train_input)\n",
    "print(decoded_train_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:42:23.464120Z",
     "start_time": "2023-06-28T00:42:23.417050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Fine Tuning T5\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import AdamW\n",
    "import argparse\n",
    "from transformers import (\n",
    "    get_linear_schedule_with_warmup\n",
    "  )\n",
    "\n",
    "class T5Tuner(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,t5model, t5tokenizer,batchsize=4):\n",
    "        super().__init__()\n",
    "        self.model = t5model\n",
    "        self.tokenizer = t5tokenizer\n",
    "        self.batch_size = batchsize\n",
    "\n",
    "    def forward( self, input_ids, attention_mask=None,\n",
    "                decoder_attention_mask=None,\n",
    "                lm_labels=None):\n",
    "\n",
    "         outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "\n",
    "         return outputs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            lm_labels=batch['labels']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        self.log('train_loss',loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            lm_labels=batch['labels']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        self.log(\"val_loss\",loss)\n",
    "        return loss\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size,\n",
    "                          num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(validation_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          num_workers=2)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=3e-4, eps=1e-8)\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:42:24.326584Z",
     "start_time": "2023-06-28T00:42:23.464526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Missing logger folder: /Users/dipteshmukherjee/Documents/GitHub/t5_Question_Answer/lightning_logs\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6edcad31260641dbb80ca795fc25d972"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'QuestionGenerationDataset' on <module '__main__' (built-in)>\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model = T5Tuner(t5_model,t5_tokenizer)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs = 1,accelerator=device)\n",
    "\n",
    "trainer.fit(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:19.047555Z",
     "start_time": "2023-06-28T00:42:24.327902Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "('t5_tokenizer/tokenizer_config.json',\n 't5_tokenizer/special_tokens_map.json',\n 't5_tokenizer/spiece.model',\n 't5_tokenizer/added_tokens.json')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "!mkdir \"t5_tokenizer\"\n",
    "!mkdir \"t5_trained_model\"\n",
    "model.model.save_pretrained('t5_trained_model')\n",
    "t5_tokenizer.save_pretrained('t5_tokenizer')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:20.352934Z",
     "start_time": "2023-06-28T00:44:19.050065Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Inference / Predictions\n",
    "trained_model_path = 't5_trained_model'\n",
    "trained_tokenizer = 't5_tokenizer'\n",
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:20.356390Z",
     "start_time": "2023-06-28T00:44:20.353744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:21.538628Z",
     "start_time": "2023-06-28T00:44:20.358347Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: Holi is considered as one of the most revered and celebrated festivals of India and it is celebrated in almost every part of the country. It is also sometimes called as the “festival of love” as on this day people get to unite together forgetting all resentments and all types of bad feeling towards each other. The great Indian festival lasts for a day and a night, which starts in the evening of Purnima or the Full Moon Day in the month of Falgun. It is celebrated with the name Holika Dahan or Choti Holi on first evening of the festival and the following day is called Holi. In different parts of the country it is known with different names. The vibrancy of colors is something that brings in a lot of positivity in our lives and Holi being the festival of colours is actually a day worth rejoicing. Holi is a famous Hindu festival that is celebrated in every part of India with utmost joy and enthusiasm. The ritual starts by lighting up the bonfire one day before the day of Holi and this process symbolizes the triumph of good over the bad. On the day of Holi people play with colours with their friends and families and in evening they show love and respect to their close ones with Abeer.\n"
     ]
    }
   ],
   "source": [
    "context =\"Holi is considered as one of the most revered and celebrated festivals of India and it is celebrated in almost every part of the country. It is also sometimes called as the “festival of love” as on this day people get to unite together forgetting all resentments and all types of bad feeling towards each other. The great Indian festival lasts for a day and a night, which starts in the evening of Purnima or the Full Moon Day in the month of Falgun. It is celebrated with the name Holika Dahan or Choti Holi on first evening of the festival and the following day is called Holi. In different parts of the country it is known with different names. The vibrancy of colors is something that brings in a lot of positivity in our lives and Holi being the festival of colours is actually a day worth rejoicing. Holi is a famous Hindu festival that is celebrated in every part of India with utmost joy and enthusiasm. The ritual starts by lighting up the bonfire one day before the day of Holi and this process symbolizes the triumph of good over the bad. On the day of Holi people play with colours with their friends and families and in evening they show love and respect to their close ones with Abeer.\"\n",
    "\n",
    "text = \"context: \"+context\n",
    "print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:21.566425Z",
     "start_time": "2023-06-28T00:44:21.548762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(text,max_length =512,padding='max_length',\n",
    "                                 truncation = True,\n",
    "                                 return_tensors=\"pt\").to(device)\n",
    "print (encoding.keys())\n",
    "input_ids,attention_mask  = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:21.763639Z",
     "start_time": "2023-06-28T00:44:21.552474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holi is a famous Hindu festival that is celebrated in every part of India\n",
      "Holi is considered as one of the most revered and celebrated festivals of India\n",
      "Holi is one of the most revered and celebrated festivals of India\n",
      "Holi is a famous Hindu festival\n",
      "Holi\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=72, # How long the generated questions should be\n",
    "    early_stopping=True,\n",
    "    num_beams=5,\n",
    "    num_return_sequences=5\n",
    ")\n",
    "\n",
    "for beam_output in beam_outputs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    print(sent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:24.532710Z",
     "start_time": "2023-06-28T00:44:21.582686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Deployment Demo\n",
    "!pip install --quiet gradio==3.9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:42.491543Z",
     "start_time": "2023-06-28T00:44:24.536089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def get_question(sentence,mdl,tknizer):\n",
    "\n",
    "  ''' function to generate questions. Takes a sentence,answer,\n",
    "      model and tokenizer\n",
    "  '''\n",
    "\n",
    "  text = \"context: {}\".format(sentence)\n",
    "  #print (text)\n",
    "  max_len = 256\n",
    "  encoding = tknizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "  outs = mdl.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  max_length=72)\n",
    "  #print(\"outputs\")\n",
    "  #print(outs)\n",
    "  for beam_output in outs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    #print(sent)\n",
    "\n",
    "  dec = [tknizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "  #print(\"decs\")\n",
    "  #print(dec)\n",
    "\n",
    "  Question = dec[0].replace(\"question:\",\"\")\n",
    "  #print(Question)\n",
    "  Answer = dec[0].replace(\"answer:\",\"\")\n",
    "  #print(Answer)\n",
    "  Question= Question.strip()\n",
    "  #Answer= Answer.strip()\n",
    "  #print(Answer)\n",
    "\n",
    "  return Question, Answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:42.507690Z",
     "start_time": "2023-06-28T00:44:42.505821Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context:  Donald Trump is an American media personality and businessman who served as the 45th president of the United States.\n",
      "question:  Donald Trump\n"
     ]
    }
   ],
   "source": [
    "context = \"Donald Trump is an American media personality and businessman who served as the 45th president of the United States.\"\n",
    "\n",
    "print(\"context: \",context)\n",
    "ques, ans = get_question(context,model,tokenizer)\n",
    "print (\"question: \",ques)\n",
    "#print (\"answer: \",ans)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:43.097454Z",
     "start_time": "2023-06-28T00:44:42.515265Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dataclass_transform() got an unexpected keyword argument 'field_specifiers'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [31]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgr\u001B[39;00m\n\u001B[1;32m      3\u001B[0m context \u001B[38;5;241m=\u001B[39m gr\u001B[38;5;241m.\u001B[39minputs\u001B[38;5;241m.\u001B[39mTextbox(lines\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,placeholder\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEnter paragraph/context here...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# answer = gr.inputs.Textbox(lines=3, placeholder=\"Enter answer/keyword here...\")\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/gradio/__init__.py:3\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpkgutil\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcomponents\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcomponents\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minputs\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01minputs\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moutputs\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moutputs\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/gradio/components.py:31\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mffmpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FFmpeg\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmarkdown_it\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MarkdownIt\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m media_data, processing_utils, utils\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mblocks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Block\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdocumentation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m document, set_documentation_group\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/gradio/processing_utils.py:20\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mffmpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FFmpeg, FFprobe, FFRuntimeError\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image, ImageOps, PngImagePlugin\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m encryptor, utils\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n\u001B[1;32m     23\u001B[0m     warnings\u001B[38;5;241m.\u001B[39msimplefilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Ignore pydub warning if ffmpeg is not installed\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/gradio/utils.py:37\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mhttpx\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel, Json, parse_obj_as\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgradio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Context\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pydantic/__init__.py:2\u001B[0m, in \u001B[0;36minit pydantic.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pydantic/dataclasses.py:48\u001B[0m, in \u001B[0;36minit pydantic.dataclasses\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pydantic/main.py:120\u001B[0m, in \u001B[0;36minit pydantic.main\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: dataclass_transform() got an unexpected keyword argument 'field_specifiers'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "context = gr.inputs.Textbox(lines=5,placeholder=\"Enter paragraph/context here...\")\n",
    "# answer = gr.inputs.Textbox(lines=3, placeholder=\"Enter answer/keyword here...\")\n",
    "question = gr.outputs.Textbox( type=\"auto\", label=\"Question\")\n",
    "answer = gr.outputs.Textbox( type=\"auto\", label=\"Answer\")\n",
    "\n",
    "def generate_question(context):\n",
    "  return get_question(context,model,tokenizer)\n",
    "\n",
    "iface = gr.Interface(\n",
    "  fn=generate_question,\n",
    "  inputs=[context],\n",
    "  outputs=question)\n",
    "  #outputs=answer)\n",
    "\n",
    "iface.launch(debug=False,share=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-28T00:44:54.257137Z",
     "start_time": "2023-06-28T00:44:43.102536Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
